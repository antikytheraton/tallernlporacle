{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#load Data\n",
    "import pandas as pd\n",
    "#data2.csv has all the information\n",
    "df=pd.read_csv(\"./data-ner.csv\")\n",
    "tags=df['tag'].tolist()[1:]\n",
    "words=df['word'].tolist()[1:]\n",
    "colors=[\"azul\",\"rojo\",\"negro\",\"plata\",\"dorado\",\"oro\"]\n",
    "models=[\"versa\",\"spark\",\"civic\",\"tsuru\",\"fusion\",\"camaro\"]\n",
    "brands=[\"nissan\",\"ford\",\"mitsubishi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def replace_wd(replace_w,stacktags,stackwords,replace_list):\n",
    "    mayor_stacktags=[\"-\",\"-\",\"-\",\"-\"]\n",
    "    mayor_stackwords=[\"-\",\"-\",\"-\",\"-\"]\n",
    "    for element in replace_list:\n",
    "        stackwords[stacktags.index(replace_w)]=element\n",
    "        mayor_stacktags=mayor_stacktags+stacktags+[\"-\",\"-\",\"-\",\"-\"]\n",
    "        mayor_stackwords=mayor_stackwords+stackwords+[\"-\",\"-\",\"-\",\"-\"]\n",
    "    return mayor_stacktags,mayor_stackwords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "endtags=[]\n",
    "endwords=[]\n",
    "stacktags=[]\n",
    "stackwords=[]\n",
    "for tag,word in zip(tags,words):\n",
    "    if tag=='-':\n",
    "        if len(stacktags)>0:\n",
    "            if \"MODELO\" in stacktags:\n",
    "                stacktags,stackwords=replace_wd(\"MODELO\",stacktags,stackwords,models)\n",
    "            if \"MARCA\" in stacktags:\n",
    "                stacktags,stackwords=replace_wd(\"MARCA\",stacktags,stackwords,brands)\n",
    "            if \"COLOR\" in stacktags:\n",
    "                stacktags,stackwords=replace_wd(\"COLOR\",stacktags,stackwords,colors)\n",
    "            endtags=endtags+stacktags\n",
    "            endwords=endwords+stackwords\n",
    "        stacktags=[]\n",
    "        stackwords=[]\n",
    "        endtags.append(\"-\")\n",
    "        endwords.append(\"-\")\n",
    "    else:\n",
    "        stacktags.append(tag)\n",
    "        stackwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dicts={}\n",
    "dicts[\"tag\"]=endtags\n",
    "dicts[\"word\"]=endwords\n",
    "pd.DataFrame.from_dict(dicts)\n",
    "df.to_csv(\"augmented.csv\", sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clasifier.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prepara_frase(tags,words):\n",
    "    features=[]\n",
    "    feature={}\n",
    "    targets=[]\n",
    "    for ind,tag in enumerate(tags):\n",
    "        if tag!='-':\n",
    "            feature['0']=words[ind-2]\n",
    "            feature['1']=words[ind-1]\n",
    "            feature['2']=words[ind]\n",
    "            feature['3']=words[ind+1]\n",
    "            feature['4']=words[ind+2]\n",
    "            features.append(feature)\n",
    "            #print feature\n",
    "            feature={}\n",
    "            #if vector[0]!='af':\n",
    "            targets.append(tag)\n",
    "            #else:\n",
    "                #targets.append('*')\n",
    "    return features,targets\n",
    "features,targets=prepara_frase(endtags,endwords)\n",
    "#Vectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.externals import joblib\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "vectorizer.fit(features)\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "transformed=vectorizer.transform(features)\n",
    "from sklearn import cross_validation\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(transformed, targets, test_size=0.1, random_state=42)\n",
    "from sklearn import svm\n",
    "lin_svc = svm.LinearSVC(C=1).fit(X_train, y_train)\n",
    "#evaluando el modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(len(X_test))\n",
    "print(accuracy_score(y_test, lin_svc.predict(X_test)))\n",
    "joblib.dump(lin_svc, 'clasifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
